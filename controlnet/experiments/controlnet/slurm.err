/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:279: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:279: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:279: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:279: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:279: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:279: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:279: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(self, tenOutgrad):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(self, tenOutgrad):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(self, tenOutgrad):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(self, tenOutgrad):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(self, tenOutgrad):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(self, tenOutgrad):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(self, tenOutgrad):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:279: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/softsplat.py:359: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(self, tenOutgrad):
/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/accelerator.py:530: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
08/14/2025 21:25:19 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 8
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: no

/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/accelerator.py:530: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
08/14/2025 21:25:19 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 8
Process index: 6
Local process index: 6
Device: cuda:6

Mixed precision type: no

/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/accelerator.py:530: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/accelerator.py:530: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
08/14/2025 21:25:19 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 8
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: no

08/14/2025 21:25:19 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 8
Process index: 5
Local process index: 5
Device: cuda:5

Mixed precision type: no

/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/accelerator.py:530: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
08/14/2025 21:25:19 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 8
Process index: 4
Local process index: 4
Device: cuda:4

Mixed precision type: no

/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/accelerator.py:530: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
08/14/2025 21:25:19 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 8
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: no

/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/accelerator.py:530: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
08/14/2025 21:25:19 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 8
Process index: 7
Local process index: 7
Device: cuda:7

Mixed precision type: no

/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/accelerator.py:530: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
08/14/2025 21:25:19 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 8
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: no

You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
{'sample_max_value', 'timestep_spacing', 'dynamic_thresholding_ratio', 'thresholding', 'variance_type', 'prediction_type', 'clip_sample_range', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
{'shift_factor', 'use_post_quant_conv', 'mid_block_add_attention', 'force_upcast', 'use_quant_conv', 'scaling_factor', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at stable-diffusion-v1-5/stable-diffusion-v1-5.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
{'only_cross_attention', 'conv_in_kernel', 'time_embedding_act_fn', 'resnet_out_scale_factor', 'mid_block_only_cross_attention', 'cross_attention_norm', 'time_cond_proj_dim', 'time_embedding_dim', 'transformer_layers_per_block', 'dual_cross_attention', 'time_embedding_type', 'dropout', 'reverse_transformer_layers_per_block', 'attention_type', 'num_class_embeds', 'conv_out_kernel', 'resnet_skip_time_act', 'addition_embed_type', 'class_embeddings_concat', 'mid_block_type', 'resnet_time_scale_shift', 'addition_embed_type_num_heads', 'encoder_hid_dim_type', 'addition_time_embed_dim', 'class_embed_type', 'num_attention_heads', 'projection_class_embeddings_input_dim', 'timestep_post_act', 'upcast_attention', 'use_linear_projection', 'encoder_hid_dim'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing UNet2DConditionModel.

All the weights of UNet2DConditionModel were initialized from the model checkpoint at stable-diffusion-v1-5/stable-diffusion-v1-5.
If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.
08/14/2025 21:25:23 - INFO - __main__ - Initializing controlnet weights from unet
08/14/2025 21:26:02 - INFO - __main__ - ***** Running training *****
08/14/2025 21:26:02 - INFO - __main__ -   Num examples = 662945
08/14/2025 21:26:02 - INFO - __main__ -   Num batches each epoch = 82869
08/14/2025 21:26:02 - INFO - __main__ -   Num Epochs = 10
08/14/2025 21:26:02 - INFO - __main__ -   Instantaneous batch size per device = 1
08/14/2025 21:26:02 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32
08/14/2025 21:26:02 - INFO - __main__ -   Gradient Accumulation steps = 4
08/14/2025 21:26:02 - INFO - __main__ -   Total optimization steps = 207180
Steps:   0%|          | 0/207180 [00:00<?, ?it/s]/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/controlnet.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/controlnet.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/controlnet.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/controlnet.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/controlnet.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/controlnet.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/controlnet.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/controlnet.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
Steps:   0%|          | 0/207180 [00:08<?, ?it/s, loss=0.00892, lr=1e-5]Steps:   0%|          | 0/207180 [00:12<?, ?it/s, loss=0.11, lr=1e-5]   Steps:   0%|          | 0/207180 [00:15<?, ?it/s, loss=0.0179, lr=1e-5]Steps:   0%|          | 1/207180 [00:19<1119:19:16, 19.45s/it, loss=0.0179, lr=1e-5]Steps:   0%|          | 1/207180 [00:19<1119:19:16, 19.45s/it, loss=0.219, lr=1e-5] Steps:   0%|          | 1/207180 [00:22<1119:19:16, 19.45s/it, loss=0.125, lr=1e-5]Steps:   0%|          | 1/207180 [00:26<1119:19:16, 19.45s/it, loss=0.255, lr=1e-5]Steps:   0%|          | 1/207180 [00:29<1119:19:16, 19.45s/it, loss=0.088, lr=1e-5]Steps:   0%|          | 2/207180 [00:33<921:28:51, 16.01s/it, loss=0.088, lr=1e-5] Steps:   0%|          | 2/207180 [00:33<921:28:51, 16.01s/it, loss=0.248, lr=1e-5]Steps:   0%|          | 2/207180 [00:36<921:28:51, 16.01s/it, loss=0.00402, lr=1e-5]Steps:   0%|          | 2/207180 [00:39<921:28:51, 16.01s/it, loss=0.167, lr=1e-5]  Steps:   0%|          | 2/207180 [00:43<921:28:51, 16.01s/it, loss=0.0662, lr=1e-5]Steps:   0%|          | 3/207180 [00:46<855:23:09, 14.86s/it, loss=0.0662, lr=1e-5]Steps:   0%|          | 3/207180 [00:46<855:23:09, 14.86s/it, loss=0.0373, lr=1e-5]Steps:   0%|          | 3/207180 [00:49<855:23:09, 14.86s/it, loss=0.0118, lr=1e-5]Steps:   0%|          | 3/207180 [00:52<855:23:09, 14.86s/it, loss=0.01, lr=1e-5]  Steps:   0%|          | 3/207180 [00:56<855:23:09, 14.86s/it, loss=0.0649, lr=1e-5]Steps:   0%|          | 4/207180 [00:59<812:25:50, 14.12s/it, loss=0.0649, lr=1e-5]Steps:   0%|          | 4/207180 [00:59<812:25:50, 14.12s/it, loss=0.461, lr=1e-5] Steps:   0%|          | 4/207180 [01:03<812:25:50, 14.12s/it, loss=0.214, lr=1e-5]Steps:   0%|          | 4/207180 [01:06<812:25:50, 14.12s/it, loss=0.0516, lr=1e-5]Steps:   0%|          | 4/207180 [01:09<812:25:50, 14.12s/it, loss=0.158, lr=1e-5] Steps:   0%|          | 5/207180 [01:13<806:09:28, 14.01s/it, loss=0.158, lr=1e-5]Steps:   0%|          | 5/207180 [01:13<806:09:28, 14.01s/it, loss=0.00752, lr=1e-5]Steps:   0%|          | 5/207180 [01:16<806:09:28, 14.01s/it, loss=0.0134, lr=1e-5] Steps:   0%|          | 5/207180 [01:20<806:09:28, 14.01s/it, loss=0.0071, lr=1e-5]Steps:   0%|          | 5/207180 [01:23<806:09:28, 14.01s/it, loss=0.53, lr=1e-5]  Steps:   0%|          | 6/207180 [01:26<796:14:02, 13.84s/it, loss=0.53, lr=1e-5]Steps:   0%|          | 6/207180 [01:26<796:14:02, 13.84s/it, loss=0.0715, lr=1e-5]Steps:   0%|          | 6/207180 [01:30<796:14:02, 13.84s/it, loss=0.23, lr=1e-5]  Steps:   0%|          | 6/207180 [01:33<796:14:02, 13.84s/it, loss=0.0134, lr=1e-5]Steps:   0%|          | 6/207180 [01:36<796:14:02, 13.84s/it, loss=0.0292, lr=1e-5]Steps:   0%|          | 7/207180 [01:39<778:46:05, 13.53s/it, loss=0.0292, lr=1e-5]Steps:   0%|          | 7/207180 [01:40<778:46:05, 13.53s/it, loss=0.287, lr=1e-5] Steps:   0%|          | 7/207180 [01:43<778:46:05, 13.53s/it, loss=0.00512, lr=1e-5]Steps:   0%|          | 7/207180 [01:46<778:46:05, 13.53s/it, loss=0.00879, lr=1e-5]Steps:   0%|          | 7/207180 [01:50<778:46:05, 13.53s/it, loss=0.234, lr=1e-5]  Steps:   0%|          | 8/207180 [01:53<781:04:39, 13.57s/it, loss=0.234, lr=1e-5]Steps:   0%|          | 8/207180 [01:53<781:04:39, 13.57s/it, loss=0.613, lr=1e-5]Steps:   0%|          | 8/207180 [01:57<781:04:39, 13.57s/it, loss=0.045, lr=1e-5]Steps:   0%|          | 8/207180 [02:00<781:04:39, 13.57s/it, loss=0.0253, lr=1e-5]Steps:   0%|          | 8/207180 [02:03<781:04:39, 13.57s/it, loss=0.00221, lr=1e-5]Steps:   0%|          | 9/207180 [02:07<787:09:53, 13.68s/it, loss=0.00221, lr=1e-5]Steps:   0%|          | 9/207180 [02:07<787:09:53, 13.68s/it, loss=0.0267, lr=1e-5] Steps:   0%|          | 9/207180 [02:10<787:09:53, 13.68s/it, loss=0.0368, lr=1e-5]Steps:   0%|          | 9/207180 [02:14<787:09:53, 13.68s/it, loss=0.00503, lr=1e-5]Steps:   0%|          | 9/207180 [02:17<787:09:53, 13.68s/it, loss=0.0438, lr=1e-5] Steps:   0%|          | 10/207180 [02:20<786:59:53, 13.68s/it, loss=0.0438, lr=1e-5]Steps:   0%|          | 10/207180 [02:21<786:59:53, 13.68s/it, loss=0.0496, lr=1e-5]Steps:   0%|          | 10/207180 [02:24<786:59:53, 13.68s/it, loss=0.0203, lr=1e-5]Steps:   0%|          | 10/207180 [02:27<786:59:53, 13.68s/it, loss=0.00676, lr=1e-5]Steps:   0%|          | 10/207180 [02:31<786:59:53, 13.68s/it, loss=0.00432, lr=1e-5]Steps:   0%|          | 11/207180 [02:34<784:26:42, 13.63s/it, loss=0.00432, lr=1e-5]Steps:   0%|          | 11/207180 [02:34<784:26:42, 13.63s/it, loss=0.145, lr=1e-5]  Steps:   0%|          | 11/207180 [02:37<784:26:42, 13.63s/it, loss=0.041, lr=1e-5]Steps:   0%|          | 11/207180 [02:41<784:26:42, 13.63s/it, loss=0.177, lr=1e-5]Steps:   0%|          | 11/207180 [02:44<784:26:42, 13.63s/it, loss=0.00252, lr=1e-5]Steps:   0%|          | 12/207180 [02:48<784:23:23, 13.63s/it, loss=0.00252, lr=1e-5]Steps:   0%|          | 12/207180 [02:48<784:23:23, 13.63s/it, loss=0.322, lr=1e-5]  Steps:   0%|          | 12/207180 [02:51<784:23:23, 13.63s/it, loss=0.012, lr=1e-5]Steps:   0%|          | 12/207180 [02:54<784:23:23, 13.63s/it, loss=0.019, lr=1e-5]Steps:   0%|          | 12/207180 [02:58<784:23:23, 13.63s/it, loss=0.11, lr=1e-5] Steps:   0%|          | 13/207180 [03:01<782:33:33, 13.60s/it, loss=0.11, lr=1e-5]Steps:   0%|          | 13/207180 [03:01<782:33:33, 13.60s/it, loss=0.252, lr=1e-5]Steps:   0%|          | 13/207180 [03:05<782:33:33, 13.60s/it, loss=0.017, lr=1e-5]Steps:   0%|          | 13/207180 [03:08<782:33:33, 13.60s/it, loss=0.389, lr=1e-5]Steps:   0%|          | 13/207180 [03:11<782:33:33, 13.60s/it, loss=0.543, lr=1e-5]Steps:   0%|          | 14/207180 [03:14<777:11:09, 13.51s/it, loss=0.543, lr=1e-5]Steps:   0%|          | 14/207180 [03:15<777:11:09, 13.51s/it, loss=0.00517, lr=1e-5]Steps:   0%|          | 14/207180 [03:18<777:11:09, 13.51s/it, loss=0.0381, lr=1e-5] Steps:   0%|          | 14/207180 [03:21<777:11:09, 13.51s/it, loss=0.00288, lr=1e-5]Steps:   0%|          | 14/207180 [03:24<777:11:09, 13.51s/it, loss=0.112, lr=1e-5]  Steps:   0%|          | 15/207180 [03:28<769:16:59, 13.37s/it, loss=0.112, lr=1e-5]Steps:   0%|          | 15/207180 [03:28<769:16:59, 13.37s/it, loss=0.0204, lr=1e-5]Steps:   0%|          | 15/207180 [03:31<769:16:59, 13.37s/it, loss=0.237, lr=1e-5] Steps:   0%|          | 15/207180 [03:35<769:16:59, 13.37s/it, loss=0.302, lr=1e-5]Steps:   0%|          | 15/207180 [03:38<769:16:59, 13.37s/it, loss=0.00943, lr=1e-5]Steps:   0%|          | 16/207180 [03:41<769:48:25, 13.38s/it, loss=0.00943, lr=1e-5]Steps:   0%|          | 16/207180 [03:41<769:48:25, 13.38s/it, loss=0.102, lr=1e-5]  Steps:   0%|          | 16/207180 [03:44<769:48:25, 13.38s/it, loss=0.0534, lr=1e-5]Steps:   0%|          | 16/207180 [03:48<769:48:25, 13.38s/it, loss=0.0177, lr=1e-5]Steps:   0%|          | 16/207180 [03:51<769:48:25, 13.38s/it, loss=0.105, lr=1e-5] Steps:   0%|          | 17/207180 [03:54<766:26:34, 13.32s/it, loss=0.105, lr=1e-5]Steps:   0%|          | 17/207180 [03:55<766:26:34, 13.32s/it, loss=0.116, lr=1e-5]Steps:   0%|          | 17/207180 [03:58<766:26:34, 13.32s/it, loss=0.318, lr=1e-5]Steps:   0%|          | 17/207180 [04:01<766:26:34, 13.32s/it, loss=0.00234, lr=1e-5]Steps:   0%|          | 17/207180 [04:04<766:26:34, 13.32s/it, loss=0.00362, lr=1e-5]Steps:   0%|          | 18/207180 [04:07<766:32:09, 13.32s/it, loss=0.00362, lr=1e-5]Steps:   0%|          | 18/207180 [04:08<766:32:09, 13.32s/it, loss=0.143, lr=1e-5]  Steps:   0%|          | 18/207180 [04:11<766:32:09, 13.32s/it, loss=0.145, lr=1e-5]Steps:   0%|          | 18/207180 [04:14<766:32:09, 13.32s/it, loss=0.227, lr=1e-5]Steps:   0%|          | 18/207180 [04:18<766:32:09, 13.32s/it, loss=0.0041, lr=1e-5]Steps:   0%|          | 19/207180 [04:21<770:40:28, 13.39s/it, loss=0.0041, lr=1e-5]Steps:   0%|          | 19/207180 [04:21<770:40:28, 13.39s/it, loss=0.236, lr=1e-5] Steps:   0%|          | 19/207180 [04:25<770:40:28, 13.39s/it, loss=0.0837, lr=1e-5]Steps:   0%|          | 19/207180 [04:28<770:40:28, 13.39s/it, loss=0.00873, lr=1e-5]Steps:   0%|          | 19/207180 [04:31<770:40:28, 13.39s/it, loss=0.0138, lr=1e-5] Steps:   0%|          | 20/207180 [04:35<776:18:09, 13.49s/it, loss=0.0138, lr=1e-5]Steps:   0%|          | 20/207180 [04:35<776:18:09, 13.49s/it, loss=0.549, lr=1e-5] Steps:   0%|          | 20/207180 [04:38<776:18:09, 13.49s/it, loss=0.441, lr=1e-5]Steps:   0%|          | 20/207180 [04:41<776:18:09, 13.49s/it, loss=0.118, lr=1e-5]Steps:   0%|          | 20/207180 [04:45<776:18:09, 13.49s/it, loss=0.00819, lr=1e-5]Steps:   0%|          | 21/207180 [04:48<770:03:37, 13.38s/it, loss=0.00819, lr=1e-5]Steps:   0%|          | 21/207180 [04:49<770:03:37, 13.38s/it, loss=0.199, lr=1e-5]  Steps:   0%|          | 21/207180 [04:52<770:03:37, 13.38s/it, loss=0.264, lr=1e-5]Steps:   0%|          | 21/207180 [04:55<770:03:37, 13.38s/it, loss=0.292, lr=1e-5]Steps:   0%|          | 21/207180 [04:58<770:03:37, 13.38s/it, loss=0.267, lr=1e-5]Steps:   0%|          | 22/207180 [05:02<776:20:38, 13.49s/it, loss=0.267, lr=1e-5]Steps:   0%|          | 22/207180 [05:02<776:20:38, 13.49s/it, loss=0.0164, lr=1e-5]Steps:   0%|          | 22/207180 [05:06<776:20:38, 13.49s/it, loss=0.0223, lr=1e-5]Steps:   0%|          | 22/207180 [05:09<776:20:38, 13.49s/it, loss=0.426, lr=1e-5] Steps:   0%|          | 22/207180 [05:12<776:20:38, 13.49s/it, loss=0.0378, lr=1e-5]Steps:   0%|          | 23/207180 [05:15<782:00:34, 13.59s/it, loss=0.0378, lr=1e-5]Steps:   0%|          | 23/207180 [05:16<782:00:34, 13.59s/it, loss=0.755, lr=1e-5] Steps:   0%|          | 23/207180 [05:19<782:00:34, 13.59s/it, loss=0.152, lr=1e-5]Steps:   0%|          | 23/207180 [05:23<782:00:34, 13.59s/it, loss=0.273, lr=1e-5]Steps:   0%|          | 23/207180 [05:26<782:00:34, 13.59s/it, loss=0.0264, lr=1e-5]Steps:   0%|          | 24/207180 [05:29<789:59:38, 13.73s/it, loss=0.0264, lr=1e-5]Steps:   0%|          | 24/207180 [05:30<789:59:38, 13.73s/it, loss=0.0149, lr=1e-5]Steps:   0%|          | 24/207180 [05:33<789:59:38, 13.73s/it, loss=0.0254, lr=1e-5]Steps:   0%|          | 24/207180 [05:36<789:59:38, 13.73s/it, loss=0.0084, lr=1e-5]Steps:   0%|          | 24/207180 [05:39<789:59:38, 13.73s/it, loss=0.0699, lr=1e-5]Steps:   0%|          | 25/207180 [05:43<778:40:14, 13.53s/it, loss=0.0699, lr=1e-5]Steps:   0%|          | 25/207180 [05:43<778:40:14, 13.53s/it, loss=0.239, lr=1e-5] Steps:   0%|          | 25/207180 [05:46<778:40:14, 13.53s/it, loss=0.0594, lr=1e-5]Steps:   0%|          | 25/207180 [05:50<778:40:14, 13.53s/it, loss=0.0505, lr=1e-5]Steps:   0%|          | 25/207180 [05:53<778:40:14, 13.53s/it, loss=0.736, lr=1e-5] Steps:   0%|          | 26/207180 [05:56<783:10:31, 13.61s/it, loss=0.736, lr=1e-5]Steps:   0%|          | 26/207180 [05:57<783:10:31, 13.61s/it, loss=0.0545, lr=1e-5]Steps:   0%|          | 26/207180 [06:00<783:10:31, 13.61s/it, loss=0.381, lr=1e-5] Steps:   0%|          | 26/207180 [06:03<783:10:31, 13.61s/it, loss=0.667, lr=1e-5]Steps:   0%|          | 26/207180 [06:07<783:10:31, 13.61s/it, loss=0.00186, lr=1e-5]Steps:   0%|          | 27/207180 [06:10<783:39:22, 13.62s/it, loss=0.00186, lr=1e-5]Steps:   0%|          | 27/207180 [06:10<783:39:22, 13.62s/it, loss=0.0655, lr=1e-5] Steps:   0%|          | 27/207180 [06:13<783:39:22, 13.62s/it, loss=0.0308, lr=1e-5]Steps:   0%|          | 27/207180 [06:17<783:39:22, 13.62s/it, loss=0.244, lr=1e-5] Steps:   0%|          | 27/207180 [06:20<783:39:22, 13.62s/it, loss=0.047, lr=1e-5]Steps:   0%|          | 28/207180 [06:23<777:56:51, 13.52s/it, loss=0.047, lr=1e-5]Steps:   0%|          | 28/207180 [06:23<777:56:51, 13.52s/it, loss=0.0297, lr=1e-5]Steps:   0%|          | 28/207180 [06:27<777:56:51, 13.52s/it, loss=0.336, lr=1e-5] Steps:   0%|          | 28/207180 [06:30<777:56:51, 13.52s/it, loss=0.0661, lr=1e-5]Steps:   0%|          | 28/207180 [06:33<777:56:51, 13.52s/it, loss=0.251, lr=1e-5] Steps:   0%|          | 29/207180 [06:36<772:46:11, 13.43s/it, loss=0.251, lr=1e-5]Steps:   0%|          | 29/207180 [06:37<772:46:11, 13.43s/it, loss=0.0344, lr=1e-5]Steps:   0%|          | 29/207180 [06:40<772:46:11, 13.43s/it, loss=0.157, lr=1e-5] Steps:   0%|          | 29/207180 [06:43<772:46:11, 13.43s/it, loss=0.564, lr=1e-5]Steps:   0%|          | 29/207180 [06:46<772:46:11, 13.43s/it, loss=0.557, lr=1e-5]Steps:   0%|          | 30/207180 [06:50<771:14:56, 13.40s/it, loss=0.557, lr=1e-5]Steps:   0%|          | 30/207180 [06:50<771:14:56, 13.40s/it, loss=0.00621, lr=1e-5]Steps:   0%|          | 30/207180 [06:53<771:14:56, 13.40s/it, loss=0.00316, lr=1e-5]Steps:   0%|          | 30/207180 [06:57<771:14:56, 13.40s/it, loss=0.147, lr=1e-5]  Steps:   0%|          | 30/207180 [07:00<771:14:56, 13.40s/it, loss=0.0954, lr=1e-5]Steps:   0%|          | 31/207180 [07:03<768:07:51, 13.35s/it, loss=0.0954, lr=1e-5]Steps:   0%|          | 31/207180 [07:03<768:07:51, 13.35s/it, loss=0.233, lr=1e-5] Steps:   0%|          | 31/207180 [07:06<768:07:51, 13.35s/it, loss=0.109, lr=1e-5]Steps:   0%|          | 31/207180 [07:10<768:07:51, 13.35s/it, loss=0.00279, lr=1e-5]Steps:   0%|          | 31/207180 [07:13<768:07:51, 13.35s/it, loss=0.0112, lr=1e-5] Steps:   0%|          | 32/207180 [07:16<764:41:32, 13.29s/it, loss=0.0112, lr=1e-5]Steps:   0%|          | 32/207180 [07:17<764:41:32, 13.29s/it, loss=0.514, lr=1e-5] Steps:   0%|          | 32/207180 [07:20<764:41:32, 13.29s/it, loss=0.083, lr=1e-5]Steps:   0%|          | 32/207180 [07:23<764:41:32, 13.29s/it, loss=0.0172, lr=1e-5]Steps:   0%|          | 32/207180 [07:27<764:41:32, 13.29s/it, loss=0.138, lr=1e-5] Steps:   0%|          | 33/207180 [07:30<770:19:40, 13.39s/it, loss=0.138, lr=1e-5]Steps:   0%|          | 33/207180 [07:30<770:19:40, 13.39s/it, loss=0.0635, lr=1e-5]Steps:   0%|          | 33/207180 [07:33<770:19:40, 13.39s/it, loss=0.00302, lr=1e-5]Steps:   0%|          | 33/207180 [07:37<770:19:40, 13.39s/it, loss=0.163, lr=1e-5]  Steps:   0%|          | 33/207180 [07:40<770:19:40, 13.39s/it, loss=0.00508, lr=1e-5]Steps:   0%|          | 34/207180 [07:43<769:20:47, 13.37s/it, loss=0.00508, lr=1e-5]Steps:   0%|          | 34/207180 [07:44<769:20:47, 13.37s/it, loss=0.0339, lr=1e-5] Steps:   0%|          | 34/207180 [07:47<769:20:47, 13.37s/it, loss=0.0942, lr=1e-5]Steps:   0%|          | 34/207180 [07:50<769:20:47, 13.37s/it, loss=0.109, lr=1e-5] Steps:   0%|          | 34/207180 [07:54<769:20:47, 13.37s/it, loss=0.0069, lr=1e-5]Steps:   0%|          | 35/207180 [07:57<779:37:43, 13.55s/it, loss=0.0069, lr=1e-5]Steps:   0%|          | 35/207180 [07:57<779:37:43, 13.55s/it, loss=0.393, lr=1e-5] Steps:   0%|          | 35/207180 [08:00<779:37:43, 13.55s/it, loss=0.0473, lr=1e-5]Steps:   0%|          | 35/207180 [08:04<779:37:43, 13.55s/it, loss=0.0372, lr=1e-5]Steps:   0%|          | 35/207180 [08:07<779:37:43, 13.55s/it, loss=0.0803, lr=1e-5]Steps:   0%|          | 36/207180 [08:10<775:11:26, 13.47s/it, loss=0.0803, lr=1e-5]Steps:   0%|          | 36/207180 [08:10<775:11:26, 13.47s/it, loss=0.0056, lr=1e-5]Steps:   0%|          | 36/207180 [08:14<775:11:26, 13.47s/it, loss=0.246, lr=1e-5] Steps:   0%|          | 36/207180 [08:17<775:11:26, 13.47s/it, loss=0.00969, lr=1e-5]Steps:   0%|          | 36/207180 [08:20<775:11:26, 13.47s/it, loss=0.372, lr=1e-5]  Steps:   0%|          | 37/207180 [08:23<769:06:01, 13.37s/it, loss=0.372, lr=1e-5]Steps:   0%|          | 37/207180 [08:24<769:06:01, 13.37s/it, loss=0.0825, lr=1e-5]Steps:   0%|          | 37/207180 [08:27<769:06:01, 13.37s/it, loss=0.0374, lr=1e-5]Steps:   0%|          | 37/207180 [08:30<769:06:01, 13.37s/it, loss=0.0224, lr=1e-5]Steps:   0%|          | 37/207180 [08:34<769:06:01, 13.37s/it, loss=0.138, lr=1e-5] Steps:   0%|          | 38/207180 [08:37<769:06:58, 13.37s/it, loss=0.138, lr=1e-5]Steps:   0%|          | 38/207180 [08:37<769:06:58, 13.37s/it, loss=0.123, lr=1e-5]Steps:   0%|          | 38/207180 [08:41<769:06:58, 13.37s/it, loss=0.0429, lr=1e-5]Steps:   0%|          | 38/207180 [08:44<769:06:58, 13.37s/it, loss=0.0109, lr=1e-5]Steps:   0%|          | 38/207180 [08:47<769:06:58, 13.37s/it, loss=0.0351, lr=1e-5]Steps:   0%|          | 39/207180 [08:51<774:59:56, 13.47s/it, loss=0.0351, lr=1e-5]Steps:   0%|          | 39/207180 [08:51<774:59:56, 13.47s/it, loss=0.122, lr=1e-5] Steps:   0%|          | 39/207180 [08:54<774:59:56, 13.47s/it, loss=0.0676, lr=1e-5]Steps:   0%|          | 39/207180 [08:58<774:59:56, 13.47s/it, loss=0.209, lr=1e-5] Steps:   0%|          | 39/207180 [09:01<774:59:56, 13.47s/it, loss=0.00476, lr=1e-5]Steps:   0%|          | 40/207180 [09:04<778:55:59, 13.54s/it, loss=0.00476, lr=1e-5]Steps:   0%|          | 40/207180 [09:04<778:55:59, 13.54s/it, loss=0.00684, lr=1e-5]Steps:   0%|          | 40/207180 [09:08<778:55:59, 13.54s/it, loss=0.0786, lr=1e-5] Steps:   0%|          | 40/207180 [09:11<778:55:59, 13.54s/it, loss=0.508, lr=1e-5] Steps:   0%|          | 40/207180 [09:14<778:55:59, 13.54s/it, loss=0.583, lr=1e-5]Steps:   0%|          | 41/207180 [09:18<776:47:01, 13.50s/it, loss=0.583, lr=1e-5]Steps:   0%|          | 41/207180 [09:18<776:47:01, 13.50s/it, loss=0.0145, lr=1e-5]Steps:   0%|          | 41/207180 [09:21<776:47:01, 13.50s/it, loss=0.0654, lr=1e-5]Steps:   0%|          | 41/207180 [09:25<776:47:01, 13.50s/it, loss=0.654, lr=1e-5] Steps:   0%|          | 41/207180 [09:28<776:47:01, 13.50s/it, loss=0.0564, lr=1e-5]Steps:   0%|          | 42/207180 [09:31<777:39:43, 13.52s/it, loss=0.0564, lr=1e-5]Steps:   0%|          | 42/207180 [09:32<777:39:43, 13.52s/it, loss=0.194, lr=1e-5] Steps:   0%|          | 42/207180 [09:35<777:39:43, 13.52s/it, loss=0.0287, lr=1e-5]Steps:   0%|          | 42/207180 [09:38<777:39:43, 13.52s/it, loss=0.00232, lr=1e-5]Steps:   0%|          | 42/207180 [09:41<777:39:43, 13.52s/it, loss=0.0371, lr=1e-5] Steps:   0%|          | 43/207180 [09:45<776:19:36, 13.49s/it, loss=0.0371, lr=1e-5]Steps:   0%|          | 43/207180 [09:45<776:19:36, 13.49s/it, loss=0.42, lr=1e-5]  Steps:   0%|          | 43/207180 [09:48<776:19:36, 13.49s/it, loss=0.00438, lr=1e-5]Steps:   0%|          | 43/207180 [09:51<776:19:36, 13.49s/it, loss=0.184, lr=1e-5]  Steps:   0%|          | 43/207180 [09:55<776:19:36, 13.49s/it, loss=0.379, lr=1e-5]Steps:   0%|          | 44/207180 [09:58<773:14:50, 13.44s/it, loss=0.379, lr=1e-5]Steps:   0%|          | 44/207180 [09:58<773:14:50, 13.44s/it, loss=0.00758, lr=1e-5]Steps:   0%|          | 44/207180 [10:01<773:14:50, 13.44s/it, loss=0.0838, lr=1e-5] Steps:   0%|          | 44/207180 [10:05<773:14:50, 13.44s/it, loss=0.28, lr=1e-5]  Steps:   0%|          | 44/207180 [10:08<773:14:50, 13.44s/it, loss=0.00495, lr=1e-5]Steps:   0%|          | 45/207180 [10:11<768:53:04, 13.36s/it, loss=0.00495, lr=1e-5]Steps:   0%|          | 45/207180 [10:11<768:53:04, 13.36s/it, loss=0.138, lr=1e-5]  Steps:   0%|          | 45/207180 [10:15<768:53:04, 13.36s/it, loss=0.42, lr=1e-5] Steps:   0%|          | 45/207180 [10:18<768:53:04, 13.36s/it, loss=0.0125, lr=1e-5]Steps:   0%|          | 45/207180 [10:21<768:53:04, 13.36s/it, loss=0.0695, lr=1e-5]Steps:   0%|          | 46/207180 [10:25<773:18:59, 13.44s/it, loss=0.0695, lr=1e-5]Steps:   0%|          | 46/207180 [10:25<773:18:59, 13.44s/it, loss=0.0701, lr=1e-5]Steps:   0%|          | 46/207180 [10:28<773:18:59, 13.44s/it, loss=0.294, lr=1e-5] Steps:   0%|          | 46/207180 [10:31<773:18:59, 13.44s/it, loss=0.0598, lr=1e-5]Steps:   0%|          | 46/207180 [10:35<773:18:59, 13.44s/it, loss=0.018, lr=1e-5] Steps:   0%|          | 47/207180 [10:38<768:23:15, 13.35s/it, loss=0.018, lr=1e-5]Steps:   0%|          | 47/207180 [10:38<768:23:15, 13.35s/it, loss=0.225, lr=1e-5]Steps:   0%|          | 47/207180 [10:41<768:23:15, 13.35s/it, loss=0.00121, lr=1e-5]Steps:   0%|          | 47/207180 [10:45<768:23:15, 13.35s/it, loss=0.158, lr=1e-5]  Steps:   0%|          | 47/207180 [10:48<768:23:15, 13.35s/it, loss=0.071, lr=1e-5]Steps:   0%|          | 48/207180 [10:51<764:12:31, 13.28s/it, loss=0.071, lr=1e-5]Steps:   0%|          | 48/207180 [10:52<764:12:31, 13.28s/it, loss=0.00872, lr=1e-5]Steps:   0%|          | 48/207180 [10:55<764:12:31, 13.28s/it, loss=0.0143, lr=1e-5] Steps:   0%|          | 48/207180 [10:58<764:12:31, 13.28s/it, loss=0.0068, lr=1e-5]Steps:   0%|          | 48/207180 [11:02<764:12:31, 13.28s/it, loss=0.169, lr=1e-5] Steps:   0%|          | 49/207180 [11:05<772:46:49, 13.43s/it, loss=0.169, lr=1e-5]Steps:   0%|          | 49/207180 [11:05<772:46:49, 13.43s/it, loss=0.0267, lr=1e-5]Steps:   0%|          | 49/207180 [11:09<772:46:49, 13.43s/it, loss=0.101, lr=1e-5] Steps:   0%|          | 49/207180 [11:12<772:46:49, 13.43s/it, loss=0.177, lr=1e-5]Steps:   0%|          | 49/207180 [11:15<772:46:49, 13.43s/it, loss=0.00495, lr=1e-5]Steps:   0%|          | 50/207180 [11:18<776:23:12, 13.49s/it, loss=0.00495, lr=1e-5]Steps:   0%|          | 50/207180 [11:19<776:23:12, 13.49s/it, loss=0.119, lr=1e-5]  Steps:   0%|          | 50/207180 [11:22<776:23:12, 13.49s/it, loss=0.128, lr=1e-5]Steps:   0%|          | 50/207180 [11:25<776:23:12, 13.49s/it, loss=0.00329, lr=1e-5]Steps:   0%|          | 50/207180 [11:29<776:23:12, 13.49s/it, loss=0.178, lr=1e-5]  Steps:   0%|          | 51/207180 [11:32<773:56:33, 13.45s/it, loss=0.178, lr=1e-5]Steps:   0%|          | 51/207180 [11:32<773:56:33, 13.45s/it, loss=0.249, lr=1e-5]Steps:   0%|          | 51/207180 [11:35<773:56:33, 13.45s/it, loss=0.0927, lr=1e-5]Steps:   0%|          | 51/207180 [11:39<773:56:33, 13.45s/it, loss=0.00417, lr=1e-5]Steps:   0%|          | 51/207180 [11:42<773:56:33, 13.45s/it, loss=0.0899, lr=1e-5] Steps:   0%|          | 52/207180 [11:45<773:27:18, 13.44s/it, loss=0.0899, lr=1e-5]Steps:   0%|          | 52/207180 [11:46<773:27:18, 13.44s/it, loss=0.0523, lr=1e-5]Steps:   0%|          | 52/207180 [11:49<773:27:18, 13.44s/it, loss=0.384, lr=1e-5] Steps:   0%|          | 52/207180 [11:52<773:27:18, 13.44s/it, loss=0.0203, lr=1e-5]Steps:   0%|          | 52/207180 [11:55<773:27:18, 13.44s/it, loss=0.598, lr=1e-5] Steps:   0%|          | 53/207180 [11:58<769:38:50, 13.38s/it, loss=0.598, lr=1e-5]Steps:   0%|          | 53/207180 [11:59<769:38:50, 13.38s/it, loss=0.12, lr=1e-5] Steps:   0%|          | 53/207180 [12:02<769:38:50, 13.38s/it, loss=0.0041, lr=1e-5]Steps:   0%|          | 53/207180 [12:05<769:38:50, 13.38s/it, loss=0.00453, lr=1e-5]Steps:   0%|          | 53/207180 [12:09<769:38:50, 13.38s/it, loss=0.0826, lr=1e-5] Steps:   0%|          | 54/207180 [12:12<770:33:26, 13.39s/it, loss=0.0826, lr=1e-5]Steps:   0%|          | 54/207180 [12:12<770:33:26, 13.39s/it, loss=0.0448, lr=1e-5]Steps:   0%|          | 54/207180 [12:15<770:33:26, 13.39s/it, loss=0.0265, lr=1e-5]Steps:   0%|          | 54/207180 [12:19<770:33:26, 13.39s/it, loss=0.00716, lr=1e-5]Steps:   0%|          | 54/207180 [12:22<770:33:26, 13.39s/it, loss=0.00819, lr=1e-5]Steps:   0%|          | 55/207180 [12:25<771:40:16, 13.41s/it, loss=0.00819, lr=1e-5]Steps:   0%|          | 55/207180 [12:25<771:40:16, 13.41s/it, loss=0.426, lr=1e-5]  Steps:   0%|          | 55/207180 [12:29<771:40:16, 13.41s/it, loss=0.00701, lr=1e-5]Steps:   0%|          | 55/207180 [12:32<771:40:16, 13.41s/it, loss=0.0548, lr=1e-5] Steps:   0%|          | 55/207180 [12:35<771:40:16, 13.41s/it, loss=0.595, lr=1e-5] Steps:   0%|          | 56/207180 [12:39<766:52:13, 13.33s/it, loss=0.595, lr=1e-5]Steps:   0%|          | 56/207180 [12:39<766:52:13, 13.33s/it, loss=0.203, lr=1e-5]Steps:   0%|          | 56/207180 [12:42<766:52:13, 13.33s/it, loss=0.00438, lr=1e-5]Steps:   0%|          | 56/207180 [12:45<766:52:13, 13.33s/it, loss=0.0769, lr=1e-5] Steps:   0%|          | 56/207180 [12:49<766:52:13, 13.33s/it, loss=0.0592, lr=1e-5]Steps:   0%|          | 57/207180 [12:52<770:14:02, 13.39s/it, loss=0.0592, lr=1e-5]Steps:   0%|          | 57/207180 [12:52<770:14:02, 13.39s/it, loss=0.136, lr=1e-5] Steps:   0%|          | 57/207180 [12:56<770:14:02, 13.39s/it, loss=0.00386, lr=1e-5]Steps:   0%|          | 57/207180 [12:59<770:14:02, 13.39s/it, loss=0.125, lr=1e-5]  Steps:   0%|          | 57/207180 [13:02<770:14:02, 13.39s/it, loss=0.00774, lr=1e-5]Steps:   0%|          | 58/207180 [13:05<767:10:28, 13.33s/it, loss=0.00774, lr=1e-5]Steps:   0%|          | 58/207180 [13:06<767:10:28, 13.33s/it, loss=0.0422, lr=1e-5] Steps:   0%|          | 58/207180 [13:09<767:10:28, 13.33s/it, loss=0.126, lr=1e-5] Steps:   0%|          | 58/207180 [13:12<767:10:28, 13.33s/it, loss=0.00403, lr=1e-5]Steps:   0%|          | 58/207180 [13:16<767:10:28, 13.33s/it, loss=0.0135, lr=1e-5] Steps:   0%|          | 59/207180 [13:19<770:50:30, 13.40s/it, loss=0.0135, lr=1e-5]Steps:   0%|          | 59/207180 [13:19<770:50:30, 13.40s/it, loss=0.00176, lr=1e-5]Steps:   0%|          | 59/207180 [13:22<770:50:30, 13.40s/it, loss=0.182, lr=1e-5]  Steps:   0%|          | 59/207180 [13:25<770:50:30, 13.40s/it, loss=0.165, lr=1e-5]Steps:   0%|          | 59/207180 [13:29<770:50:30, 13.40s/it, loss=0.0326, lr=1e-5]Steps:   0%|          | 60/207180 [13:32<771:08:02, 13.40s/it, loss=0.0326, lr=1e-5]Steps:   0%|          | 60/207180 [13:32<771:08:02, 13.40s/it, loss=0.136, lr=1e-5] Steps:   0%|          | 60/207180 [13:36<771:08:02, 13.40s/it, loss=0.267, lr=1e-5]Steps:   0%|          | 60/207180 [13:39<771:08:02, 13.40s/it, loss=0.0107, lr=1e-5]Steps:   0%|          | 60/207180 [13:42<771:08:02, 13.40s/it, loss=0.08, lr=1e-5]  Steps:   0%|          | 61/207180 [13:46<770:32:00, 13.39s/it, loss=0.08, lr=1e-5]Steps:   0%|          | 61/207180 [13:46<770:32:00, 13.39s/it, loss=0.315, lr=1e-5]Steps:   0%|          | 61/207180 [13:49<770:32:00, 13.39s/it, loss=0.00999, lr=1e-5]Steps:   0%|          | 61/207180 [13:52<770:32:00, 13.39s/it, loss=0.175, lr=1e-5]  Steps:   0%|          | 61/207180 [13:55<770:32:00, 13.39s/it, loss=0.0142, lr=1e-5]Steps:   0%|          | 62/207180 [13:59<765:46:49, 13.31s/it, loss=0.0142, lr=1e-5]Steps:   0%|          | 62/207180 [13:59<765:46:49, 13.31s/it, loss=0.027, lr=1e-5] Steps:   0%|          | 62/207180 [14:02<765:46:49, 13.31s/it, loss=0.00723, lr=1e-5]Steps:   0%|          | 62/207180 [14:05<765:46:49, 13.31s/it, loss=0.0759, lr=1e-5] Steps:   0%|          | 62/207180 [14:09<765:46:49, 13.31s/it, loss=0.0602, lr=1e-5]Steps:   0%|          | 63/207180 [14:12<766:36:55, 13.32s/it, loss=0.0602, lr=1e-5]Steps:   0%|          | 63/207180 [14:12<766:36:55, 13.32s/it, loss=0.0526, lr=1e-5]Steps:   0%|          | 63/207180 [14:16<766:36:55, 13.32s/it, loss=0.00341, lr=1e-5]Steps:   0%|          | 63/207180 [14:19<766:36:55, 13.32s/it, loss=0.0292, lr=1e-5] Steps:   0%|          | 63/207180 [14:22<766:36:55, 13.32s/it, loss=0.0943, lr=1e-5]Steps:   0%|          | 64/207180 [14:25<763:21:41, 13.27s/it, loss=0.0943, lr=1e-5]Steps:   0%|          | 64/207180 [14:26<763:21:41, 13.27s/it, loss=0.142, lr=1e-5] Steps:   0%|          | 64/207180 [14:29<763:21:41, 13.27s/it, loss=0.169, lr=1e-5]Steps:   0%|          | 64/207180 [14:32<763:21:41, 13.27s/it, loss=0.0765, lr=1e-5]Steps:   0%|          | 64/207180 [14:35<763:21:41, 13.27s/it, loss=0.0328, lr=1e-5]Steps:   0%|          | 65/207180 [14:38<762:53:02, 13.26s/it, loss=0.0328, lr=1e-5]Steps:   0%|          | 65/207180 [14:39<762:53:02, 13.26s/it, loss=0.0214, lr=1e-5]Steps:   0%|          | 65/207180 [14:42<762:53:02, 13.26s/it, loss=0.0985, lr=1e-5]Steps:   0%|          | 65/207180 [14:46<762:53:02, 13.26s/it, loss=0.123, lr=1e-5] Steps:   0%|          | 65/207180 [14:49<762:53:02, 13.26s/it, loss=0.00395, lr=1e-5]Steps:   0%|          | 66/207180 [14:52<767:58:03, 13.35s/it, loss=0.00395, lr=1e-5]Steps:   0%|          | 66/207180 [14:52<767:58:03, 13.35s/it, loss=0.655, lr=1e-5]  Steps:   0%|          | 66/207180 [14:56<767:58:03, 13.35s/it, loss=0.0545, lr=1e-5]Steps:   0%|          | 66/207180 [14:59<767:58:03, 13.35s/it, loss=0.154, lr=1e-5] Steps:   0%|          | 66/207180 [15:02<767:58:03, 13.35s/it, loss=0.241, lr=1e-5]Steps:   0%|          | 67/207180 [15:06<771:19:04, 13.41s/it, loss=0.241, lr=1e-5]Steps:   0%|          | 67/207180 [15:06<771:19:04, 13.41s/it, loss=0.01, lr=1e-5] Steps:   0%|          | 67/207180 [15:09<771:19:04, 13.41s/it, loss=0.00656, lr=1e-5]Steps:   0%|          | 67/207180 [15:12<771:19:04, 13.41s/it, loss=0.0176, lr=1e-5] Steps:   0%|          | 67/207180 [15:15<771:19:04, 13.41s/it, loss=0.0927, lr=1e-5]Steps:   0%|          | 68/207180 [15:19<765:16:56, 13.30s/it, loss=0.0927, lr=1e-5]Steps:   0%|          | 68/207180 [15:19<765:16:56, 13.30s/it, loss=0.0111, lr=1e-5]Steps:   0%|          | 68/207180 [15:22<765:16:56, 13.30s/it, loss=0.134, lr=1e-5] Steps:   0%|          | 68/207180 [15:26<765:16:56, 13.30s/it, loss=0.00466, lr=1e-5]Steps:   0%|          | 68/207180 [15:29<765:16:56, 13.30s/it, loss=0.199, lr=1e-5]  Steps:   0%|          | 69/207180 [15:32<768:17:22, 13.35s/it, loss=0.199, lr=1e-5]Steps:   0%|          | 69/207180 [15:32<768:17:22, 13.35s/it, loss=0.0134, lr=1e-5]Steps:   0%|          | 69/207180 [15:36<768:17:22, 13.35s/it, loss=0.00383, lr=1e-5]Steps:   0%|          | 69/207180 [15:39<768:17:22, 13.35s/it, loss=0.068, lr=1e-5]  Steps:   0%|          | 69/207180 [15:42<768:17:22, 13.35s/it, loss=0.0712, lr=1e-5]Steps:   0%|          | 70/207180 [15:45<764:02:57, 13.28s/it, loss=0.0712, lr=1e-5]Steps:   0%|          | 70/207180 [15:46<764:02:57, 13.28s/it, loss=0.0717, lr=1e-5]Steps:   0%|          | 70/207180 [15:49<764:02:57, 13.28s/it, loss=0.0315, lr=1e-5]Steps:   0%|          | 70/207180 [15:52<764:02:57, 13.28s/it, loss=0.00768, lr=1e-5]Steps:   0%|          | 70/207180 [15:55<764:02:57, 13.28s/it, loss=0.0482, lr=1e-5] Steps:   0%|          | 71/207180 [15:59<765:17:28, 13.30s/it, loss=0.0482, lr=1e-5]Steps:   0%|          | 71/207180 [15:59<765:17:28, 13.30s/it, loss=0.00454, lr=1e-5]Steps:   0%|          | 71/207180 [16:02<765:17:28, 13.30s/it, loss=0.121, lr=1e-5]  Steps:   0%|          | 71/207180 [16:05<765:17:28, 13.30s/it, loss=0.227, lr=1e-5]Steps:   0%|          | 71/207180 [16:09<765:17:28, 13.30s/it, loss=0.431, lr=1e-5]Steps:   0%|          | 72/207180 [16:12<767:17:13, 13.34s/it, loss=0.431, lr=1e-5]Steps:   0%|          | 72/207180 [16:12<767:17:13, 13.34s/it, loss=0.103, lr=1e-5]Steps:   0%|          | 72/207180 [16:15<767:17:13, 13.34s/it, loss=0.0927, lr=1e-5]Steps:   0%|          | 72/207180 [16:19<767:17:13, 13.34s/it, loss=0.245, lr=1e-5] Steps:   0%|          | 72/207180 [16:22<767:17:13, 13.34s/it, loss=0.281, lr=1e-5]Steps:   0%|          | 73/207180 [16:25<763:53:57, 13.28s/it, loss=0.281, lr=1e-5]Steps:   0%|          | 73/207180 [16:26<763:53:57, 13.28s/it, loss=0.0199, lr=1e-5]Steps:   0%|          | 73/207180 [16:29<763:53:57, 13.28s/it, loss=0.00369, lr=1e-5]Steps:   0%|          | 73/207180 [16:32<763:53:57, 13.28s/it, loss=0.0495, lr=1e-5] Steps:   0%|          | 73/207180 [16:35<763:53:57, 13.28s/it, loss=0.044, lr=1e-5] Steps:   0%|          | 74/207180 [16:39<769:10:15, 13.37s/it, loss=0.044, lr=1e-5]Steps:   0%|          | 74/207180 [16:39<769:10:15, 13.37s/it, loss=0.024, lr=1e-5]Steps:   0%|          | 74/207180 [16:42<769:10:15, 13.37s/it, loss=0.276, lr=1e-5]Steps:   0%|          | 74/207180 [16:46<769:10:15, 13.37s/it, loss=0.54, lr=1e-5] Steps:   0%|          | 74/207180 [16:49<769:10:15, 13.37s/it, loss=0.561, lr=1e-5]Steps:   0%|          | 75/207180 [16:52<772:09:32, 13.42s/it, loss=0.561, lr=1e-5]Steps:   0%|          | 75/207180 [16:52<772:09:32, 13.42s/it, loss=0.139, lr=1e-5]Steps:   0%|          | 75/207180 [16:56<772:09:32, 13.42s/it, loss=0.059, lr=1e-5]Steps:   0%|          | 75/207180 [16:59<772:09:32, 13.42s/it, loss=0.295, lr=1e-5]Steps:   0%|          | 75/207180 [17:02<772:09:32, 13.42s/it, loss=0.0704, lr=1e-5]Steps:   0%|          | 76/207180 [17:05<764:30:54, 13.29s/it, loss=0.0704, lr=1e-5]Steps:   0%|          | 76/207180 [17:06<764:30:54, 13.29s/it, loss=0.164, lr=1e-5] Steps:   0%|          | 76/207180 [17:09<764:30:54, 13.29s/it, loss=0.0131, lr=1e-5]Steps:   0%|          | 76/207180 [17:12<764:30:54, 13.29s/it, loss=0.00574, lr=1e-5]Steps:   0%|          | 76/207180 [17:15<764:30:54, 13.29s/it, loss=0.258, lr=1e-5]  Steps:   0%|          | 77/207180 [17:19<769:30:27, 13.38s/it, loss=0.258, lr=1e-5]Steps:   0%|          | 77/207180 [17:19<769:30:27, 13.38s/it, loss=0.00733, lr=1e-5]Steps:   0%|          | 77/207180 [17:22<769:30:27, 13.38s/it, loss=0.217, lr=1e-5]  Steps:   0%|          | 77/207180 [17:25<769:30:27, 13.38s/it, loss=0.00863, lr=1e-5]Steps:   0%|          | 77/207180 [17:29<769:30:27, 13.38s/it, loss=0.144, lr=1e-5]  Steps:   0%|          | 78/207180 [17:32<764:43:04, 13.29s/it, loss=0.144, lr=1e-5]Steps:   0%|          | 78/207180 [17:32<764:43:04, 13.29s/it, loss=0.381, lr=1e-5]Steps:   0%|          | 78/207180 [17:36<764:43:04, 13.29s/it, loss=0.00272, lr=1e-5]Steps:   0%|          | 78/207180 [17:39<764:43:04, 13.29s/it, loss=0.132, lr=1e-5]  Steps:   0%|          | 78/207180 [17:42<764:43:04, 13.29s/it, loss=0.13, lr=1e-5] Steps:   0%|          | 79/207180 [17:45<765:59:12, 13.32s/it, loss=0.13, lr=1e-5]Steps:   0%|          | 79/207180 [17:46<765:59:12, 13.32s/it, loss=0.00309, lr=1e-5]Steps:   0%|          | 79/207180 [17:49<765:59:12, 13.32s/it, loss=0.191, lr=1e-5]  Steps:   0%|          | 79/207180 [17:52<765:59:12, 13.32s/it, loss=0.127, lr=1e-5]Steps:   0%|          | 79/207180 [17:55<765:59:12, 13.32s/it, loss=0.31, lr=1e-5] Steps:   0%|          | 80/207180 [17:59<766:14:15, 13.32s/it, loss=0.31, lr=1e-5]Steps:   0%|          | 80/207180 [17:59<766:14:15, 13.32s/it, loss=0.208, lr=1e-5]Steps:   0%|          | 80/207180 [18:02<766:14:15, 13.32s/it, loss=0.156, lr=1e-5]Steps:   0%|          | 80/207180 [18:05<766:14:15, 13.32s/it, loss=0.351, lr=1e-5]Steps:   0%|          | 80/207180 [18:09<766:14:15, 13.32s/it, loss=0.00493, lr=1e-5]Steps:   0%|          | 81/207180 [18:12<769:08:33, 13.37s/it, loss=0.00493, lr=1e-5]Steps:   0%|          | 81/207180 [18:12<769:08:33, 13.37s/it, loss=0.709, lr=1e-5]  Steps:   0%|          | 81/207180 [18:15<769:08:33, 13.37s/it, loss=0.0221, lr=1e-5]Steps:   0%|          | 81/207180 [18:19<769:08:33, 13.37s/it, loss=0.093, lr=1e-5] Steps:   0%|          | 81/207180 [18:22<769:08:33, 13.37s/it, loss=0.025, lr=1e-5]Steps:   0%|          | 82/207180 [18:25<768:41:26, 13.36s/it, loss=0.025, lr=1e-5]Steps:   0%|          | 82/207180 [18:26<768:41:26, 13.36s/it, loss=0.102, lr=1e-5]Steps:   0%|          | 82/207180 [18:29<768:41:26, 13.36s/it, loss=0.393, lr=1e-5]Steps:   0%|          | 82/207180 [18:32<768:41:26, 13.36s/it, loss=0.258, lr=1e-5]Steps:   0%|          | 82/207180 [18:35<768:41:26, 13.36s/it, loss=0.756, lr=1e-5]Steps:   0%|          | 83/207180 [18:39<764:52:03, 13.30s/it, loss=0.756, lr=1e-5]Steps:   0%|          | 83/207180 [18:39<764:52:03, 13.30s/it, loss=0.0833, lr=1e-5]Steps:   0%|          | 83/207180 [18:42<764:52:03, 13.30s/it, loss=0.0217, lr=1e-5]Steps:   0%|          | 83/207180 [18:45<764:52:03, 13.30s/it, loss=0.19, lr=1e-5]  Steps:   0%|          | 83/207180 [18:49<764:52:03, 13.30s/it, loss=0.0368, lr=1e-5]Steps:   0%|          | 84/207180 [18:52<763:22:11, 13.27s/it, loss=0.0368, lr=1e-5]Steps:   0%|          | 84/207180 [18:52<763:22:11, 13.27s/it, loss=0.0406, lr=1e-5]Steps:   0%|          | 84/207180 [18:55<763:22:11, 13.27s/it, loss=0.27, lr=1e-5]  Steps:   0%|          | 84/207180 [18:59<763:22:11, 13.27s/it, loss=0.0429, lr=1e-5]Steps:   0%|          | 84/207180 [19:02<763:22:11, 13.27s/it, loss=0.114, lr=1e-5] Steps:   0%|          | 85/207180 [19:05<766:31:53, 13.32s/it, loss=0.114, lr=1e-5]Steps:   0%|          | 85/207180 [19:05<766:31:53, 13.32s/it, loss=0.016, lr=1e-5]Steps:   0%|          | 85/207180 [19:09<766:31:53, 13.32s/it, loss=0.24, lr=1e-5] Steps:   0%|          | 85/207180 [19:12<766:31:53, 13.32s/it, loss=0.182, lr=1e-5]Steps:   0%|          | 85/207180 [19:15<766:31:53, 13.32s/it, loss=0.189, lr=1e-5]Steps:   0%|          | 86/207180 [19:19<766:43:05, 13.33s/it, loss=0.189, lr=1e-5]Steps:   0%|          | 86/207180 [19:19<766:43:05, 13.33s/it, loss=0.304, lr=1e-5]Steps:   0%|          | 86/207180 [19:22<766:43:05, 13.33s/it, loss=0.0605, lr=1e-5]Steps:   0%|          | 86/207180 [19:25<766:43:05, 13.33s/it, loss=0.0371, lr=1e-5]Steps:   0%|          | 86/207180 [19:29<766:43:05, 13.33s/it, loss=0.26, lr=1e-5]  Steps:   0%|          | 87/207180 [19:32<768:03:27, 13.35s/it, loss=0.26, lr=1e-5]Steps:   0%|          | 87/207180 [19:32<768:03:27, 13.35s/it, loss=0.00636, lr=1e-5]Steps:   0%|          | 87/207180 [19:35<768:03:27, 13.35s/it, loss=0.365, lr=1e-5]  Steps:   0%|          | 87/207180 [19:39<768:03:27, 13.35s/it, loss=0.0108, lr=1e-5]Steps:   0%|          | 87/207180 [19:42<768:03:27, 13.35s/it, loss=0.239, lr=1e-5] Steps:   0%|          | 88/207180 [19:45<765:00:22, 13.30s/it, loss=0.239, lr=1e-5]Steps:   0%|          | 88/207180 [19:45<765:00:22, 13.30s/it, loss=0.00807, lr=1e-5]Steps:   0%|          | 88/207180 [19:49<765:00:22, 13.30s/it, loss=0.302, lr=1e-5]  Steps:   0%|          | 88/207180 [19:52<765:00:22, 13.30s/it, loss=0.171, lr=1e-5]Steps:   0%|          | 88/207180 [19:55<765:00:22, 13.30s/it, loss=0.243, lr=1e-5]Steps:   0%|          | 89/207180 [19:58<764:27:20, 13.29s/it, loss=0.243, lr=1e-5]Steps:   0%|          | 89/207180 [19:59<764:27:20, 13.29s/it, loss=0.00645, lr=1e-5]Steps:   0%|          | 89/207180 [20:02<764:27:20, 13.29s/it, loss=0.0403, lr=1e-5] Steps:   0%|          | 89/207180 [20:05<764:27:20, 13.29s/it, loss=0.629, lr=1e-5] Steps:   0%|          | 89/207180 [20:08<764:27:20, 13.29s/it, loss=0.0524, lr=1e-5]Steps:   0%|          | 90/207180 [20:12<763:14:14, 13.27s/it, loss=0.0524, lr=1e-5]Steps:   0%|          | 90/207180 [20:12<763:14:14, 13.27s/it, loss=0.0235, lr=1e-5]Steps:   0%|          | 90/207180 [20:15<763:14:14, 13.27s/it, loss=0.29, lr=1e-5]  Steps:   0%|          | 90/207180 [20:19<763:14:14, 13.27s/it, loss=0.422, lr=1e-5]Steps:   0%|          | 90/207180 [20:22<763:14:14, 13.27s/it, loss=0.205, lr=1e-5]Steps:   0%|          | 91/207180 [20:25<766:56:20, 13.33s/it, loss=0.205, lr=1e-5]Steps:   0%|          | 91/207180 [20:25<766:56:20, 13.33s/it, loss=0.0416, lr=1e-5]Steps:   0%|          | 91/207180 [20:29<766:56:20, 13.33s/it, loss=0.00963, lr=1e-5]Steps:   0%|          | 91/207180 [20:32<766:56:20, 13.33s/it, loss=0.0143, lr=1e-5] Steps:   0%|          | 91/207180 [20:35<766:56:20, 13.33s/it, loss=0.179, lr=1e-5] Steps:   0%|          | 92/207180 [20:38<765:54:56, 13.31s/it, loss=0.179, lr=1e-5]Steps:   0%|          | 92/207180 [20:39<765:54:56, 13.31s/it, loss=0.0663, lr=1e-5]Steps:   0%|          | 92/207180 [20:42<765:54:56, 13.31s/it, loss=0.0156, lr=1e-5]Steps:   0%|          | 92/207180 [20:45<765:54:56, 13.31s/it, loss=0.095, lr=1e-5] Steps:   0%|          | 92/207180 [20:49<765:54:56, 13.31s/it, loss=0.00433, lr=1e-5]Steps:   0%|          | 93/207180 [20:52<773:18:13, 13.44s/it, loss=0.00433, lr=1e-5]Steps:   0%|          | 93/207180 [20:52<773:18:13, 13.44s/it, loss=0.143, lr=1e-5]  Steps:   0%|          | 93/207180 [20:55<773:18:13, 13.44s/it, loss=0.33, lr=1e-5] Steps:   0%|          | 93/207180 [20:59<773:18:13, 13.44s/it, loss=0.0148, lr=1e-5]Steps:   0%|          | 93/207180 [21:02<773:18:13, 13.44s/it, loss=0.0157, lr=1e-5]Steps:   0%|          | 94/207180 [21:05<765:32:22, 13.31s/it, loss=0.0157, lr=1e-5]Steps:   0%|          | 94/207180 [21:06<765:32:22, 13.31s/it, loss=0.00337, lr=1e-5]Steps:   0%|          | 94/207180 [21:09<765:32:22, 13.31s/it, loss=0.103, lr=1e-5]  Steps:   0%|          | 94/207180 [21:12<765:32:22, 13.31s/it, loss=0.00837, lr=1e-5]Steps:   0%|          | 94/207180 [21:15<765:32:22, 13.31s/it, loss=0.084, lr=1e-5]  Steps:   0%|          | 95/207180 [21:19<771:07:01, 13.41s/it, loss=0.084, lr=1e-5]Steps:   0%|          | 95/207180 [21:19<771:07:01, 13.41s/it, loss=0.088, lr=1e-5]Steps:   0%|          | 95/207180 [21:22<771:07:01, 13.41s/it, loss=0.41, lr=1e-5] Steps:   0%|          | 95/207180 [21:25<771:07:01, 13.41s/it, loss=0.0178, lr=1e-5]Steps:   0%|          | 95/207180 [21:29<771:07:01, 13.41s/it, loss=0.00738, lr=1e-5]Steps:   0%|          | 96/207180 [21:32<765:29:05, 13.31s/it, loss=0.00738, lr=1e-5]Steps:   0%|          | 96/207180 [21:32<765:29:05, 13.31s/it, loss=0.22, lr=1e-5]   Steps:   0%|          | 96/207180 [21:35<765:29:05, 13.31s/it, loss=0.0403, lr=1e-5]Steps:   0%|          | 96/207180 [21:39<765:29:05, 13.31s/it, loss=0.0235, lr=1e-5]Steps:   0%|          | 96/207180 [21:42<765:29:05, 13.31s/it, loss=0.238, lr=1e-5] Steps:   0%|          | 97/207180 [21:45<764:13:40, 13.29s/it, loss=0.238, lr=1e-5]Steps:   0%|          | 97/207180 [21:46<764:13:40, 13.29s/it, loss=0.0669, lr=1e-5]Steps:   0%|          | 97/207180 [21:49<764:13:40, 13.29s/it, loss=0.00655, lr=1e-5]Steps:   0%|          | 97/207180 [21:52<764:13:40, 13.29s/it, loss=0.00922, lr=1e-5]Steps:   0%|          | 97/207180 [21:55<764:13:40, 13.29s/it, loss=0.0337, lr=1e-5] Steps:   0%|          | 98/207180 [21:59<767:23:14, 13.34s/it, loss=0.0337, lr=1e-5]Steps:   0%|          | 98/207180 [21:59<767:23:14, 13.34s/it, loss=0.0135, lr=1e-5]Steps:   0%|          | 98/207180 [22:02<767:23:14, 13.34s/it, loss=0.062, lr=1e-5] Steps:   0%|          | 98/207180 [22:05<767:23:14, 13.34s/it, loss=0.023, lr=1e-5]Steps:   0%|          | 98/207180 [22:09<767:23:14, 13.34s/it, loss=0.442, lr=1e-5]Steps:   0%|          | 99/207180 [22:12<767:25:05, 13.34s/it, loss=0.442, lr=1e-5]Steps:   0%|          | 99/207180 [22:12<767:25:05, 13.34s/it, loss=0.0339, lr=1e-5]Steps:   0%|          | 99/207180 [22:16<767:25:05, 13.34s/it, loss=0.183, lr=1e-5] Steps:   0%|          | 99/207180 [22:19<767:25:05, 13.34s/it, loss=0.0723, lr=1e-5]Steps:   0%|          | 99/207180 [22:22<767:25:05, 13.34s/it, loss=0.0789, lr=1e-5]Steps:   0%|          | 100/207180 [22:25<767:35:26, 13.34s/it, loss=0.0789, lr=1e-5]08/14/2025 21:48:28 - INFO - __main__ - Running validation... 
{'requires_safety_checker', 'image_encoder', 'controlnet'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stable-diffusion-v1-5/stable-diffusion-v1-5.
Loading pipeline components...: 100%|| 6/6 [00:00<00:00, 2685.50it/s]
Expected types for controlnet: (<class 'diffusers.models.controlnets.controlnet.ControlNetModel'>, typing.List[diffusers.models.controlnets.controlnet.ControlNetModel], typing.Tuple[diffusers.models.controlnets.controlnet.ControlNetModel], <class 'diffusers.models.controlnets.multicontrolnet.MultiControlNetModel'>), got <class 'controlnet.ControlNetModel'>.
You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .
{'timestep_spacing', 'lower_order_final', 'predict_x0', 'use_flow_sigmas', 'use_dynamic_shifting', 'rescale_betas_zero_snr', 'sample_max_value', 'disable_corrector', 'solver_order', 'use_karras_sigmas', 'solver_p', 'solver_type', 'thresholding', 'flow_shift', 'prediction_type', 'final_sigmas_type', 'dynamic_thresholding_ratio', 'use_beta_sigmas', 'use_exponential_sigmas', 'time_shift_type'} was not found in config. Values will be initialized to default values.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/train_controlnet.py", line 1264, in <module>
[rank0]:     main(args)
[rank0]:   File "/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/train_controlnet.py", line 1204, in main
[rank0]:     image_logs = log_validation(
[rank0]:   File "/data/maryamsana_98/UniControl_Video_Interpolation/diffusers/examples/controlnet/train_controlnet.py", line 139, in log_validation
[rank0]:     image = pipeline(
[rank0]:   File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/diffusers/pipelines/controlnet/pipeline_controlnet.py", line 1085, in __call__
[rank0]:     self.check_inputs(
[rank0]:   File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/diffusers/pipelines/controlnet/pipeline_controlnet.py", line 686, in check_inputs
[rank0]:     assert False
[rank0]: AssertionError
Steps:   0%|          | 100/207180 [22:26<774:49:21, 13.47s/it, loss=0.0789, lr=1e-5]
[rank0]:[W814 21:48:30.290102498 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W0814 21:48:32.051000 914473 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 914508 closing signal SIGTERM
W0814 21:48:32.053000 914473 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 914509 closing signal SIGTERM
W0814 21:48:32.054000 914473 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 914510 closing signal SIGTERM
W0814 21:48:32.054000 914473 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 914511 closing signal SIGTERM
W0814 21:48:32.081000 914473 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 914512 closing signal SIGTERM
W0814 21:48:32.094000 914473 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 914513 closing signal SIGTERM
W0814 21:48:32.129000 914473 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 914514 closing signal SIGTERM
E0814 21:48:33.057000 914473 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 914507) of binary: /data/maryamsana_98/anaconda3/envs/diffusers_env/bin/python3.10
Traceback (most recent call last):
  File "/data/maryamsana_98/anaconda3/envs/diffusers_env/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1226, in launch_command
    multi_gpu_launcher(args)
  File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/maryamsana_98/anaconda3/envs/diffusers_env/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_controlnet.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-08-14_21:48:32
  host      : vll1
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 914507)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
