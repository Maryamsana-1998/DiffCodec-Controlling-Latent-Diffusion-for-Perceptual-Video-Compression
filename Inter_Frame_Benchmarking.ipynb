{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9c6ad50-c17d-47f3-9284-876436944a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if './' not in sys.path:\n",
    "\tsys.path.append('./')\n",
    " \n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from test_utils import calculate_metrics_batch\n",
    "\n",
    "\n",
    "# === Utility Functions ===\n",
    "def get_png_paths(folder):\n",
    "    return sorted([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(\".png\")])\n",
    "\n",
    "\n",
    "def get_every_other(lst, skip=2):\n",
    "    return [img for i, img in enumerate(lst) if i % skip != 0]\n",
    "\n",
    "def load_image_pairs(original_paths, pred_paths, resize=False):\n",
    "    images_a, images_b = [], []\n",
    "    for p1, p2 in zip(original_paths, pred_paths):\n",
    "        if os.path.exists(p1) and os.path.exists(p2):\n",
    "            img_a = Image.open(p1).convert(\"RGB\")\n",
    "            img_b = Image.open(p2).convert(\"RGB\")\n",
    "            if resize:\n",
    "                img_b = img_b.resize((1920, 1080), Image.Resampling.LANCZOS)\n",
    "            images_a.append(img_a)\n",
    "            images_b.append(img_b)\n",
    "        else:\n",
    "            print(f\"⚠️ Missing: {p1} or {p2}\")\n",
    "    return images_a, images_b\n",
    "\n",
    "def evaluate_video(original_folder, pred_folder):\n",
    "    original_paths = get_every_other(get_png_paths(original_folder))\n",
    "    pred_paths = get_every_other(get_png_paths(os.path.join(pred_folder)))\n",
    "    print(pred_paths[:10])\n",
    "\n",
    "    orig_imgs, pred_imgs = load_image_pairs(original_paths, pred_paths)\n",
    "\n",
    "    if orig_imgs and pred_imgs:\n",
    "        metrics = calculate_metrics_batch(orig_imgs, pred_imgs)\n",
    "        print(\"✅ Metrics:\", metrics)\n",
    "        return metrics\n",
    "    print(\"❌ No valid pairs.\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e561e-1e03-4eb6-9afe-a1f7e74d86d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hevc_gop2/Beauty/bpp_0.1/frame_002.png', 'hevc_gop2/Beauty/bpp_0.1/frame_004.png', 'hevc_gop2/Beauty/bpp_0.1/frame_006.png', 'hevc_gop2/Beauty/bpp_0.1/frame_008.png', 'hevc_gop2/Beauty/bpp_0.1/frame_010.png', 'hevc_gop2/Beauty/bpp_0.1/frame_012.png', 'hevc_gop2/Beauty/bpp_0.1/frame_014.png', 'hevc_gop2/Beauty/bpp_0.1/frame_016.png', 'hevc_gop2/Beauty/bpp_0.1/frame_018.png', 'hevc_gop2/Beauty/bpp_0.1/frame_020.png']\n",
      "✅ Metrics: {'PSNR': 22.23662833372752, 'MS-SSIM': 0.753349956125021, 'LPIPS': 0.1316205527012547, 'FID': 0.16762728989124298}\n",
      "['hevc_gop2/Beauty/bpp_0.006/frame_002.png', 'hevc_gop2/Beauty/bpp_0.006/frame_004.png', 'hevc_gop2/Beauty/bpp_0.006/frame_006.png', 'hevc_gop2/Beauty/bpp_0.006/frame_008.png', 'hevc_gop2/Beauty/bpp_0.006/frame_010.png', 'hevc_gop2/Beauty/bpp_0.006/frame_012.png', 'hevc_gop2/Beauty/bpp_0.006/frame_014.png', 'hevc_gop2/Beauty/bpp_0.006/frame_016.png', 'hevc_gop2/Beauty/bpp_0.006/frame_018.png', 'hevc_gop2/Beauty/bpp_0.006/frame_020.png']\n",
      "✅ Metrics: {'PSNR': 22.41557975610097, 'MS-SSIM': 0.7599002371231715, 'LPIPS': 0.20948428536454836, 'FID': 1.2845579385757446}\n",
      "['hevc_gop2/Beauty/bpp_0.05/frame_002.png', 'hevc_gop2/Beauty/bpp_0.05/frame_004.png', 'hevc_gop2/Beauty/bpp_0.05/frame_006.png', 'hevc_gop2/Beauty/bpp_0.05/frame_008.png', 'hevc_gop2/Beauty/bpp_0.05/frame_010.png', 'hevc_gop2/Beauty/bpp_0.05/frame_012.png', 'hevc_gop2/Beauty/bpp_0.05/frame_014.png', 'hevc_gop2/Beauty/bpp_0.05/frame_016.png', 'hevc_gop2/Beauty/bpp_0.05/frame_018.png', 'hevc_gop2/Beauty/bpp_0.05/frame_020.png']\n",
      "✅ Metrics: {'PSNR': 22.256047407786053, 'MS-SSIM': 0.7554127735396227, 'LPIPS': 0.14714576862752438, 'FID': 0.3063923418521881}\n",
      "['preds_gop2_q4/Beauty/im00002_pred.png', 'preds_gop2_q4/Beauty/im00004_pred.png', 'preds_gop2_q4/Beauty/im00006_pred.png', 'preds_gop2_q4/Beauty/im00008_pred.png', 'preds_gop2_q4/Beauty/im00010_pred.png', 'preds_gop2_q4/Beauty/im00012_pred.png', 'preds_gop2_q4/Beauty/im00014_pred.png', 'preds_gop2_q4/Beauty/im00016_pred.png', 'preds_gop2_q4/Beauty/im00018_pred.png', 'preds_gop2_q4/Beauty/im00020_pred.png']\n",
      "✅ Metrics: {'PSNR': 23.556054375388406, 'MS-SSIM': 0.9085902165282856, 'LPIPS': 0.10684566233645786, 'FID': 0.7025522589683533}\n",
      "['hevc_gop2/Bosphorus/bpp_0.1/frame_002.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_004.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_006.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_008.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_010.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_012.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_014.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_016.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_018.png', 'hevc_gop2/Bosphorus/bpp_0.1/frame_020.png']\n",
      "✅ Metrics: {'PSNR': 18.4448086420695, 'MS-SSIM': 0.4626696463674307, 'LPIPS': 0.19817551597952843, 'FID': 0.04558485373854637}\n",
      "['hevc_gop2/Bosphorus/bpp_0.006/frame_002.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_004.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_006.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_008.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_010.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_012.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_014.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_016.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_018.png', 'hevc_gop2/Bosphorus/bpp_0.006/frame_020.png']\n",
      "✅ Metrics: {'PSNR': 18.72160001595815, 'MS-SSIM': 0.4779718903203805, 'LPIPS': 0.35994764727850753, 'FID': 3.2128634452819824}\n",
      "['hevc_gop2/Bosphorus/bpp_0.05/frame_002.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_004.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_006.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_008.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_010.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_012.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_014.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_016.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_018.png', 'hevc_gop2/Bosphorus/bpp_0.05/frame_020.png']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of videos\n",
    "videos = ['Beauty', 'Bosphorus', 'ShakeNDry', 'HoneyBee']\n",
    "\n",
    "# GOP size and frame info\n",
    "gop_size = 2\n",
    "height, width = 1024, 1920\n",
    "inter_frames_per_video = 48\n",
    "\n",
    "# Bits per video\n",
    "hevc_bits_dict = {\n",
    "    'Beauty': [131347, 4820, 70935],\n",
    "    'Bosphorus': [11285, 3787, 7356],\n",
    "    'ShakeNDry': [102325, 4451, 11174],\n",
    "    'HoneyBee': [8505, 4102, 5280]\n",
    "}\n",
    "\n",
    "model_bits_dict = {\n",
    "    'Beauty': [1222, 1082],\n",
    "    'Bosphorus': [950, 708],\n",
    "    'ShakeNDry': [556, 564],\n",
    "    'HoneyBee': [556, 740]\n",
    "}\n",
    "\n",
    "# Labels for HEVC folders\n",
    "bpp_dict = [0.1, 0.006, 0.05]\n",
    "\n",
    "# Store results as list of dicts per video\n",
    "results = {}\n",
    "\n",
    "for video in videos:\n",
    "    results[video] = []\n",
    "\n",
    "    # HEVC results\n",
    "    for i, bits in enumerate(hevc_bits_dict[video]):\n",
    "        bpp = bits * 8 / (inter_frames_per_video * height * width)\n",
    "        folder = str(bpp_dict[i])\n",
    "\n",
    "        metrics = evaluate_video(\n",
    "            f'data/{video}/images/',\n",
    "            f'hevc_gop{gop_size}/{video}/bpp_{folder}/'\n",
    "        )\n",
    "\n",
    "        results[video].append({\n",
    "            'codec': 'hevc',\n",
    "            'bpp': bpp,\n",
    "            'bits': bits,\n",
    "            **metrics   # merge PSNR, MS-SSIM, LPIPS, FID\n",
    "        })\n",
    "\n",
    "    # Our model results\n",
    "    bits_total = sum(model_bits_dict[video]) * 8 * inter_frames_per_video\n",
    "    bpp_model = bits_total / (inter_frames_per_video * height * width)\n",
    "\n",
    "    metrics = evaluate_video(\n",
    "        f'data/{video}/images/',\n",
    "        f'preds_gop{gop_size}_q4/{video}/'\n",
    "    )\n",
    "\n",
    "    results[video].append({\n",
    "        'codec': 'ours',\n",
    "        'bpp': bpp_model,\n",
    "        'bits': sum(model_bits_dict[video]),\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "# Save results\n",
    "np.save('inter_frame_results.npy', results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06536e6b-b879-4b6c-a0ce-aea522638630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
